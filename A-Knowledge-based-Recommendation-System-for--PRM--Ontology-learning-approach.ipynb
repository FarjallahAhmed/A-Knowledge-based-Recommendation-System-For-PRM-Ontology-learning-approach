{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47264bfc-9a53-4598-a47f-4a155fdc4eb5",
   "metadata": {},
   "source": [
    "# A Knowledge based Recommendation System for Project Mangement Ontology learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0060197-734f-4b1d-a843-e92d078d9074",
   "metadata": {},
   "source": [
    "The procedure of ontology construction can be done in one of three ways: manual construction; cooperative construction (need the human intervention during the constructing process) and (semi-) automatic construction which considered the Ontology Learning (OL) approach. OL from text is the process for acquiring and representing knowledge from text [structured (database), semi-structured (XML file) and unstructured (.txt, pdf, etc)] to be in machine-understandable form [OWL, RDF (Resource Description Framework), or RDFS (Resource Description Framework Schema)], by applying a set of methods and techniques (NLP, data mining, and machine learning).\n",
    "\n",
    "-Natural Language Processing via NLTK and Spacy matcher linguistic-based preprocessing technique: (1)Tokénization and normalization (2) part-of –speech tagging (POS), (3)posTagger, (4) stopwords, Lemmatization (Stemming), (5) chunking. levenshetein measure, TF-IDF measure, leveithen measure, cosine similarity measure, topic modeling LDA, n-gram, -Recommenadtions techniques based on ML : hiaachical clutering, classification, KNN, etc -Performance measures: Precision, Recall and F measure, -Programmation: Python, java; -Semantic web language/Tool: OWL2, RDF and SWRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248be3-c002-44e7-97f0-dff71d2d9604",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062c767c-7213-414f-99ca-803ca25bb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import span\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import pos_tag, RegexpParser\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from rdflib.namespace import DC, DCTERMS, DOAP, FOAF, OWL, RDF, RDFS, SKOS, VOID, XMLNS\n",
    "from rdflib import URIRef, BNode, Literal, Namespace, Graph\n",
    "from rdflib.extras import describer\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "\n",
    "#nltk.download('conll2000')\n",
    "from nltk.corpus import conll2000\n",
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.chunk import ChunkParserI\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from keybert import KeyBERT\n",
    "\n",
    "\n",
    "#kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "#stop = stopwords.words('english')\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604730a6-4399-491a-a234-850b9a286e61",
   "metadata": {},
   "source": [
    "# Util Funtions For Text-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd44a7d-29a3-4a89-8bb1-22f497ba3601",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da0d9e7-6711-4849-b80c-82d46c7d5d7d",
   "metadata": {},
   "source": [
    "# Import Data From The PDF File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71d6fb-3aae-4041-9fdb-be2dfbd391fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d5f9ee-5f95-49ba-ab13-453e1c6a8faf",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957113b-52f1-4cff-a57b-e2d97fe7471e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9497f3-791a-413c-8ca2-a2b64663b7b2",
   "metadata": {},
   "source": [
    "# Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ed6cf-bd48-4808-bb8f-be37dc3e4270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c76e383-18c9-4f32-9dcb-faeeb91db9ba",
   "metadata": {},
   "source": [
    "# OWL File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8cf13-ed72-4c31-93e4-b19663173c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e82f77-5192-4e72-975e-5a65d8df1a7e",
   "metadata": {},
   "source": [
    "# Model Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e08c61-1a5b-4d0a-842b-09fe64d27e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
