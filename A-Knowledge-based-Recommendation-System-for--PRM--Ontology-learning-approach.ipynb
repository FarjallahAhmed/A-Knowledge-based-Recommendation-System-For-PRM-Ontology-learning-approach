{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47264bfc-9a53-4598-a47f-4a155fdc4eb5",
   "metadata": {},
   "source": [
    "# A Knowledge based Recommendation System for Project Mangement Ontology learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0060197-734f-4b1d-a843-e92d078d9074",
   "metadata": {},
   "source": [
    "The procedure of ontology construction can be done in one of three ways: manual construction; cooperative construction (need the human intervention during the constructing process) and (semi-) automatic construction which considered the Ontology Learning (OL) approach. OL from text is the process for acquiring and representing knowledge from text [structured (database), semi-structured (XML file) and unstructured (.txt, pdf, etc)] to be in machine-understandable form [OWL, RDF (Resource Description Framework), or RDFS (Resource Description Framework Schema)], by applying a set of methods and techniques (NLP, data mining, and machine learning).\n",
    "\n",
    "-Natural Language Processing via NLTK and Spacy matcher linguistic-based preprocessing technique: (1)Tokénization and normalization (2) part-of –speech tagging (POS), (3)posTagger, (4) stopwords, Lemmatization (Stemming), (5) chunking. levenshetein measure, TF-IDF measure, leveithen measure, cosine similarity measure, topic modeling LDA, n-gram, -Recommenadtions techniques based on ML : hiaachical clutering, classification, KNN, etc -Performance measures: Precision, Recall and F measure, -Programmation: Python, java; -Semantic web language/Tool: OWL2, RDF and SWRL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7248be3-c002-44e7-97f0-dff71d2d9604",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "062c767c-7213-414f-99ca-803ca25bb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, fitz\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import span\n",
    "from spacy import displacy\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer,SnowballStemmer\n",
    "from nltk.corpus import wordnet, stopwords\n",
    "from nltk import pos_tag, RegexpParser\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from rdflib.namespace import DC, DCTERMS, DOAP, FOAF, OWL, RDF, RDFS, SKOS, VOID, XMLNS\n",
    "from rdflib import URIRef, BNode, Literal, Namespace, Graph\n",
    "from rdflib.extras import describer\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "\n",
    "#nltk.download('conll2000')\n",
    "from nltk.corpus import conll2000\n",
    "from nltk.tag import UnigramTagger, BigramTagger\n",
    "from nltk.chunk import ChunkParserI\n",
    "\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from keybert import KeyBERT\n",
    "\n",
    "\n",
    "#kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "\n",
    "\n",
    "#stop = stopwords.words('english')\n",
    "#nlp = spacy.load(\"en_core_web_sm\")\n",
    "#nltk.download('omw-1.4')\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604730a6-4399-491a-a234-850b9a286e61",
   "metadata": {},
   "source": [
    "# Util Funtions For Text-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd44a7d-29a3-4a89-8bb1-22f497ba3601",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    \"\"\"\n",
    "        Remove the punctuation\n",
    "    \"\"\"\n",
    "    return re.sub(r'[]!\"$%&\\'()*+/:;=#@?[\\\\^_`{|}~-]+', \" \", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77b47a5-eb60-4de4-b9b1-1fabcb5c72fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_number(text):\n",
    "    \"\"\"\n",
    "        Remove the number\n",
    "    \"\"\"\n",
    "    pattern = r'[0-9]'\n",
    "    # Match all digits in the string and replace them with an empty string\n",
    "    new_string = re.sub(pattern, ' ', text)\n",
    "\n",
    "    return new_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a70dc3b-918a-4d11-a7d6-ec721349c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    \"\"\"\n",
    "        Remove non-ASCII characters \n",
    "    \"\"\"\n",
    "    return re.sub(r'[^\\x00-\\x7f]',r' ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb4837e1-a2fc-4a5c-b025-bdf8d9a0c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_lineBreak(text):\n",
    "    \"\"\"\n",
    "        Remove line break\n",
    "    \"\"\"\n",
    "    return re.sub(\"\\n\",\" \",text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e6b2bc1-5d96-438b-a5c7-67af805c358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowerCase(text):\n",
    "    \"\"\"\n",
    "        Transform all the text to lower case\n",
    "    \"\"\"\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f52ca0-fed3-4ce5-93f2-478e17239bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_extra_whitespaces_func(text):\n",
    "    '''\n",
    "    Removes extra whitespaces from a string, if present\n",
    "    \n",
    "    Args:\n",
    "        text (str): String to which the function is to be applied, string\n",
    "    \n",
    "    Returns:\n",
    "        Clean string without extra whitespaces\n",
    "    ''' \n",
    "    return re.sub(r'^\\s*|\\s\\s*', ' ', text).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1793f1-6765-4660-964b-f5289e83de43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf7133-b8db-4a5b-a64a-e60ad2260667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22988ba-63ac-44ef-bf7d-43943f309f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2d6242-288d-4a1b-8567-03bac8d50091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20f99b-8ca6-42cc-8cc0-41303d23267f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7da0d9e7-6711-4849-b80c-82d46c7d5d7d",
   "metadata": {},
   "source": [
    "# Import Data From The PDF File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf0e2bc-6bc7-4c44-868a-d2a19fd685c3",
   "metadata": {},
   "source": [
    "## 1. Retrive The Text From The PMBOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d71d6fb-3aae-4041-9fdb-be2dfbd391fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get The text from the pdf file with the library fitz\n",
    "fdoc = fitz.open(\"PMBOK6-2017.pdf\")\n",
    "header = \"Header\"  # text in header\n",
    "footer = \"Page %i of %i\"  # text in footer\n",
    "page = []\n",
    "for i  in range(0,573):\n",
    "    page.append(fdoc[i].get_text())  # insert header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb8aedd-0942-4fea-933d-35e07e8737c2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# 2. Get the text for each chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5459eb2-2129-4f85-b843-58130bf49fca",
   "metadata": {},
   "source": [
    "### 2.1 Initialize Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "085c1273-5761-48ba-84da-752d2e960159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variable represent each chapter that we will work with \n",
    "scope = []\n",
    "schedule = []\n",
    "cost = []\n",
    "\n",
    "# variable represent title that we get from each chapter and the variable with contient the whole text that we will work with \n",
    "scope_title = []\n",
    "scope_title_without_number = []\n",
    "scope_text = ' '\n",
    "scope_content = []\n",
    "\n",
    "schedule_title = []\n",
    "schedule_title_without_number = []\n",
    "schedule_text = ' '\n",
    "schedule_content = []\n",
    "\n",
    "cost_title = []\n",
    "cost_title_without_number = []\n",
    "cost_text = ' '\n",
    "cost_content = []\n",
    "\n",
    "figures_scope = []\n",
    "figures_schedule = []\n",
    "figures_cost = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0c3822-ae91-4937-9618-3410470e8b0a",
   "metadata": {},
   "source": [
    "### 2.2 Project scope management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f92d0b26-72dd-4572-b88b-00507c475ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(164,207):\n",
    "    p = re.sub('Not For Distribution, Sale or Reproduction.', ' ', page[i])\n",
    "    p = re.sub('[0-9]+\\s\\sPart 1 - Guide', ' ', p)\n",
    "    scope.append(p)\n",
    "    scope_title.append(re.findall(\"[0-9].*[A-Z]\\n\",p))\n",
    "    figures_scope.append(re.findall(\"Figure\\s[0-9]-[0-9]{1,2}.\\s[A-Z]{1}.*\",p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a7e0b3a-5e8e-4191-bc1d-d83a3dae3a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(scope)):\n",
    "    scope_text = scope_text + scope[i]\n",
    "scope_text = scope_text + ' endchapter'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3c4489-92f6-436c-b3c5-3a0ecaec034d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfd5970-02d1-4e73-b30e-e6bdd4cfa9a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d060e2f-3718-43d2-808b-f0c8e41c760d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1d5f9ee-5f95-49ba-ab13-453e1c6a8faf",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957113b-52f1-4cff-a57b-e2d97fe7471e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9497f3-791a-413c-8ca2-a2b64663b7b2",
   "metadata": {},
   "source": [
    "# Final DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96ed6cf-bd48-4808-bb8f-be37dc3e4270",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c76e383-18c9-4f32-9dcb-faeeb91db9ba",
   "metadata": {},
   "source": [
    "# OWL File Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a8cf13-ed72-4c31-93e4-b19663173c69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6e82f77-5192-4e72-975e-5a65d8df1a7e",
   "metadata": {},
   "source": [
    "# Model Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e08c61-1a5b-4d0a-842b-09fe64d27e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
